{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ebce63",
   "metadata": {},
   "source": [
    "# DSA210 Term Project — Part 3: Machine Learning (GPR → Bitcoin & Gold)\n",
    "\n",
    "This notebook trains multiple regression models to predict **Bitcoin** and **Gold** returns using **Geopolitical Risk (GPR)** indicators.\n",
    "\n",
    "## What you need\n",
    "- A processed dataset CSV produced in Part 2 (or earlier) named: `processed_gpr_btc_gold.csv`\n",
    "- Columns expected:\n",
    "  - Features: `GPR, GPRH, GPRT, GPR_LAG1, GPR_LAG3, GPR_ROLL3`\n",
    "  - Targets: `btc_return, gold_return`\n",
    "\n",
    "> If your column names differ, edit the `features` list and target column names in the **Data Setup** cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Imports\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sns.set_context(\"talk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) PART B — Load & Clean 3 Datasets (GPR + Bitcoin + Gold)\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- (1) Helper: robust CSV/XLS loading (local first, then GitHub raw) ---\n",
    "def read_any(path_local, github_raw_url=None, **kwargs):\n",
    "    \"\"\"Try reading from local path first; if it fails and github_raw_url is provided, read from GitHub raw.\"\"\"\n",
    "    try:\n",
    "        if path_local.lower().endswith(('.xls', '.xlsx')):\n",
    "            return pd.read_excel(path_local, **kwargs)\n",
    "        return pd.read_csv(path_local, **kwargs)\n",
    "    except Exception as e:\n",
    "        if github_raw_url is None:\n",
    "            raise\n",
    "        print(f\"Local read failed for {path_local} -> trying GitHub raw...\")\n",
    "        if github_raw_url.lower().endswith(('.xls', '.xlsx')):\n",
    "            return pd.read_excel(github_raw_url, **kwargs)\n",
    "        return pd.read_csv(github_raw_url, **kwargs)\n",
    "\n",
    "# ===========================================================\n",
    "# A) GPR (Geopolitical Risk) — Excel (.xls)\n",
    "# ===========================================================\n",
    "GPR_PATH_LOCAL = \"data_gpr_export.xls\"   # put next to the notebook OR use your repo path like: data/data_gpr_export.xls\n",
    "GPR_PATH_GITHUB = None  # optional: raw GitHub link if you want\n",
    "\n",
    "df_gpr_raw = read_any(GPR_PATH_LOCAL, GPR_PATH_GITHUB)\n",
    "\n",
    "# --- Clean GPR ---\n",
    "df_gpr = df_gpr_raw.copy()\n",
    "\n",
    "# 1) Identify date column\n",
    "possible_date_cols = [c for c in df_gpr.columns if str(c).lower() in [\"date\", \"dates\", \"time\", \"month\", \"timestamp\"]]\n",
    "if possible_date_cols:\n",
    "    date_col = possible_date_cols[0]\n",
    "else:\n",
    "    # if the first column looks like a date, use it\n",
    "    date_col = df_gpr.columns[0]\n",
    "\n",
    "df_gpr[date_col] = pd.to_datetime(df_gpr[date_col], errors=\"coerce\")\n",
    "df_gpr = df_gpr.dropna(subset=[date_col]).sort_values(date_col)\n",
    "df_gpr = df_gpr.rename(columns={date_col: \"Date\"})\n",
    "\n",
    "# 2) Standardize expected GPR columns (adapt if your file uses different names)\n",
    "rename_map = {}\n",
    "for c in df_gpr.columns:\n",
    "    lc = str(c).strip().lower()\n",
    "    if lc in [\"gpr\", \"gpr index\", \"geopolitical risk\"]: rename_map[c] = \"GPR\"\n",
    "    if lc in [\"gprh\", \"gpr_h\", \"gpr high\", \"gpr headline\"]: rename_map[c] = \"GPRH\"\n",
    "    if lc in [\"gprt\", \"gpr_t\", \"gpr threats\"]: rename_map[c] = \"GPRT\"\n",
    "df_gpr = df_gpr.rename(columns=rename_map)\n",
    "\n",
    "# Keep only Date + available GPR columns\n",
    "keep_gpr_cols = [c for c in [\"Date\", \"GPR\", \"GPRH\", \"GPRT\"] if c in df_gpr.columns]\n",
    "df_gpr = df_gpr[keep_gpr_cols].copy()\n",
    "\n",
    "# Convert to numeric (some excel exports have commas/strings)\n",
    "for c in [\"GPR\", \"GPRH\", \"GPRT\"]:\n",
    "    if c in df_gpr.columns:\n",
    "        df_gpr[c] = pd.to_numeric(df_gpr[c], errors=\"coerce\")\n",
    "\n",
    "# Remove duplicates and set index\n",
    "df_gpr = df_gpr.drop_duplicates(subset=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "\n",
    "# If GPR is monthly, align to daily by forward-filling to business days\n",
    "# (we'll ultimately merge with daily BTC/Gold)\n",
    "df_gpr = df_gpr.asfreq('B').ffill()\n",
    "\n",
    "print(\"GPR cleaned:\", df_gpr.shape, \"columns:\", list(df_gpr.columns))\n",
    "\n",
    "# ===========================================================\n",
    "# B) Bitcoin Prices — CSV\n",
    "# ===========================================================\n",
    "# Use your own file names; the code tries to be flexible.\n",
    "BTC_PATH_LOCAL = \"btc.csv\"   # e.g., BTC-USD.csv (Yahoo) or your own export\n",
    "BTC_PATH_GITHUB = None\n",
    "\n",
    "df_btc_raw = read_any(BTC_PATH_LOCAL, BTC_PATH_GITHUB)\n",
    "\n",
    "df_btc = df_btc_raw.copy()\n",
    "\n",
    "# Standardize Date column\n",
    "btc_date_candidates = [c for c in df_btc.columns if str(c).lower() in [\"date\", \"time\", \"timestamp\"]]\n",
    "btc_date_col = btc_date_candidates[0] if btc_date_candidates else df_btc.columns[0]\n",
    "df_btc[btc_date_col] = pd.to_datetime(df_btc[btc_date_col], errors=\"coerce\")\n",
    "df_btc = df_btc.dropna(subset=[btc_date_col]).sort_values(btc_date_col)\n",
    "df_btc = df_btc.rename(columns={btc_date_col: \"Date\"}).set_index(\"Date\")\n",
    "\n",
    "# Choose price column (Adj Close preferred)\n",
    "price_candidates = [c for c in df_btc.columns if str(c).lower() in [\"adj close\", \"adj_close\", \"close\", \"price\"]]\n",
    "btc_price_col = price_candidates[0] if price_candidates else df_btc.columns[-1]\n",
    "df_btc[btc_price_col] = pd.to_numeric(df_btc[btc_price_col], errors=\"coerce\")\n",
    "df_btc = df_btc[[btc_price_col]].rename(columns={btc_price_col: \"BTC_Price\"}).dropna()\n",
    "\n",
    "# Daily log returns (more stable)\n",
    "df_btc[\"btc_return\"] = np.log(df_btc[\"BTC_Price\"]).diff()\n",
    "df_btc = df_btc.asfreq('B').ffill()\n",
    "\n",
    "print(\"BTC cleaned:\", df_btc.shape)\n",
    "\n",
    "# ===========================================================\n",
    "# C) Gold Prices — CSV\n",
    "# ===========================================================\n",
    "GOLD_PATH_LOCAL = \"gold.csv\"  # e.g., GC=F.csv (Yahoo) or LBMA series export\n",
    "GOLD_PATH_GITHUB = None\n",
    "\n",
    "df_gold_raw = read_any(GOLD_PATH_LOCAL, GOLD_PATH_GITHUB)\n",
    "\n",
    "df_gold = df_gold_raw.copy()\n",
    "\n",
    "gold_date_candidates = [c for c in df_gold.columns if str(c).lower() in [\"date\", \"time\", \"timestamp\"]]\n",
    "gold_date_col = gold_date_candidates[0] if gold_date_candidates else df_gold.columns[0]\n",
    "df_gold[gold_date_col] = pd.to_datetime(df_gold[gold_date_col], errors=\"coerce\")\n",
    "df_gold = df_gold.dropna(subset=[gold_date_col]).sort_values(gold_date_col)\n",
    "df_gold = df_gold.rename(columns={gold_date_col: \"Date\"}).set_index(\"Date\")\n",
    "\n",
    "gold_price_candidates = [c for c in df_gold.columns if str(c).lower() in [\"adj close\", \"adj_close\", \"close\", \"price\"]]\n",
    "gold_price_col = gold_price_candidates[0] if gold_price_candidates else df_gold.columns[-1]\n",
    "df_gold[gold_price_col] = pd.to_numeric(df_gold[gold_price_col], errors=\"coerce\")\n",
    "df_gold = df_gold[[gold_price_col]].rename(columns={gold_price_col: \"Gold_Price\"}).dropna()\n",
    "\n",
    "df_gold[\"gold_return\"] = np.log(df_gold[\"Gold_Price\"]).diff()\n",
    "df_gold = df_gold.asfreq('B').ffill()\n",
    "\n",
    "print(\"Gold cleaned:\", df_gold.shape)\n",
    "\n",
    "# ===========================================================\n",
    "# D) Merge & Feature Engineering (create ONE modeling table)\n",
    "# ===========================================================\n",
    "df = df_gpr.join(df_btc[[\"btc_return\"]], how=\"inner\").join(df_gold[[\"gold_return\"]], how=\"inner\")\n",
    "\n",
    "# Optional: drop first NA due to diff()\n",
    "df = df.dropna()\n",
    "\n",
    "# --- GPR features (lags + rolling mean) ---\n",
    "# Use whichever GPR columns exist\n",
    "base_gpr_col = \"GPR\" if \"GPR\" in df.columns else df.columns[0]\n",
    "\n",
    "df[\"GPR_LAG1\"] = df[base_gpr_col].shift(1)\n",
    "df[\"GPR_LAG3\"] = df[base_gpr_col].shift(3)\n",
    "df[\"GPR_ROLL3\"] = df[base_gpr_col].rolling(3).mean()\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Final merged dataset:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2.5) Modeling Table Setup (Features + Targets)\n",
    "# =========================\n",
    "# Targets: daily log returns\n",
    "y_btc = df['btc_return']\n",
    "y_gold = df['gold_return']\n",
    "\n",
    "# Features: all columns except targets\n",
    "X = df.drop(columns=['btc_return','gold_return'])\n",
    "\n",
    "print('Feature columns:', list(X.columns))\n",
    "print('X shape:', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d84ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Time-aware Train/Test split\n",
    "# =========================\n",
    "split = int(len(df) * 0.7)\n",
    "\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_btc_train, y_btc_test = y_btc.iloc[:split], y_btc.iloc[split:]\n",
    "y_gold_train, y_gold_test = y_gold.iloc[:split], y_gold.iloc[split:]\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"| Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0543295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Standardization\n",
    "# =========================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb981e8",
   "metadata": {},
   "source": [
    "## Models\n",
    "We train three models:\n",
    "- Linear Regression (baseline)\n",
    "- Ridge Regression (regularized linear)\n",
    "- Random Forest Regressor (non-linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Model definitions\n",
    "# =========================\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf758aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helper: Train & evaluate\n",
    "# =========================\n",
    "def train_and_evaluate(target_name, y_train, y_test):\n",
    "    rows = []\n",
    "    trained = {}\n",
    "    preds = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        r2 = float(r2_score(y_test, y_pred))\n",
    "\n",
    "        rows.append({\"Asset\": target_name, \"Model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
    "        trained[name] = model\n",
    "        preds[name] = y_pred\n",
    "    return pd.DataFrame(rows), trained, preds\n",
    "\n",
    "results_btc, trained_btc, preds_btc = train_and_evaluate(\"Bitcoin\", y_btc_train, y_btc_test)\n",
    "results_gold, trained_gold, preds_gold = train_and_evaluate(\"Gold\", y_gold_train, y_gold_test)\n",
    "\n",
    "results = pd.concat([results_btc, results_gold], ignore_index=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) Performance comparison (R2)\n",
    "# =========================\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=results, x=\"R2\", y=\"Model\", hue=\"Asset\")\n",
    "plt.title(\"Model Performance Comparison (R2)\")\n",
    "plt.xlim(-0.2, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=results, x=\"RMSE\", y=\"Model\", hue=\"Asset\")\n",
    "plt.title(\"Model Performance Comparison (RMSE)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) Diagnostic plots (Actual vs Predicted + Residuals)\n",
    "# =========================\n",
    "def plot_performance(model_name, y_true, y_pred, asset_name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Actual vs Pred\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.6, ax=axes[0])\n",
    "    min_val, max_val = min(float(y_true.min()), float(np.min(y_pred))), max(float(y_true.max()), float(np.max(y_pred)))\n",
    "    axes[0].plot([min_val, max_val], [min_val, max_val], linestyle=\"--\", linewidth=2)\n",
    "    axes[0].set_title(f\"{asset_name} — {model_name}: Actual vs Predicted\")\n",
    "    axes[0].set_xlabel(\"Actual Return\")\n",
    "    axes[0].set_ylabel(\"Predicted Return\")\n",
    "\n",
    "    # Residuals\n",
    "    residuals = y_true - y_pred\n",
    "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.6, ax=axes[1])\n",
    "    axes[1].axhline(0, linestyle=\"--\", linewidth=2)\n",
    "    axes[1].set_title(f\"{asset_name} — {model_name}: Residual Plot\")\n",
    "    axes[1].set_xlabel(\"Predicted Return\")\n",
    "    axes[1].set_ylabel(\"Residuals (Actual - Predicted)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Bitcoin plots\n",
    "for name, y_pred in preds_btc.items():\n",
    "    plot_performance(name, y_btc_test.reset_index(drop=True), pd.Series(y_pred), \"Bitcoin\")\n",
    "\n",
    "# Gold plots\n",
    "for name, y_pred in preds_gold.items():\n",
    "    plot_performance(name, y_gold_test.reset_index(drop=True), pd.Series(y_pred), \"Gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 8) Feature importance (Random Forest)\n",
    "# =========================\n",
    "def plot_rf_importance(trained_model, title):\n",
    "    importances = pd.Series(trained_model.feature_importances_, index=features).sort_values()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    importances.plot(kind=\"barh\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_rf_importance(trained_btc[\"Random Forest\"], \"Bitcoin — Random Forest Feature Importance\")\n",
    "plot_rf_importance(trained_gold[\"Random Forest\"], \"Gold — Random Forest Feature Importance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c543481a",
   "metadata": {},
   "source": [
    "## Simple scenario analysis (High GPR)\n",
    "This function predicts returns under a hypothetical high-risk environment by setting GPR/GPRH/GPRT to chosen values and mirroring them into lag/rolling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab93100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 9) Scenario prediction helper\n",
    "# =========================\n",
    "def predict_high_gpr_scenario(gpr, gprh, gprt, asset=\"Bitcoin\"):\n",
    "    input_df = pd.DataFrame([{\n",
    "        \"GPR\": gpr,\n",
    "        \"GPRH\": gprh,\n",
    "        \"GPRT\": gprt,\n",
    "        \"GPR_LAG1\": gpr,\n",
    "        \"GPR_LAG3\": gpr,\n",
    "        \"GPR_ROLL3\": gpr\n",
    "    }])[features]\n",
    "\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "\n",
    "    if asset.lower() == \"bitcoin\":\n",
    "        trained = trained_btc\n",
    "        print(\"\\n--- HIGH GPR SCENARIO (Bitcoin) ---\")\n",
    "    else:\n",
    "        trained = trained_gold\n",
    "        print(\"\\n--- HIGH GPR SCENARIO (Gold) ---\")\n",
    "\n",
    "    print(f\"GPR={gpr}, GPRH={gprh}, GPRT={gprt}\")\n",
    "    for name, model in trained.items():\n",
    "        pred = float(model.predict(input_scaled)[0])\n",
    "        print(f\"{name} prediction: {pred:.6f}\")\n",
    "\n",
    "# Example: adjust values based on your dataset scale (e.g., try df['GPR'].quantile(0.9))\n",
    "predict_high_gpr_scenario(gpr=float(df[\"GPR\"].quantile(0.9)),\n",
    "                          gprh=float(df[\"GPRH\"].quantile(0.9)),\n",
    "                          gprt=float(df[\"GPRT\"].quantile(0.9)),\n",
    "                          asset=\"Bitcoin\")\n",
    "predict_high_gpr_scenario(gpr=float(df[\"GPR\"].quantile(0.9)),\n",
    "                          gprh=float(df[\"GPRH\"].quantile(0.9)),\n",
    "                          gprt=float(df[\"GPRT\"].quantile(0.9)),\n",
    "                          asset=\"Gold\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b7157",
   "metadata": {},
   "source": [
    "## Export results table for your report\n",
    "This saves `part3_model_results.csv` which you can reference in your write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22680079",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"part3_model_results.csv\", index=False)\n",
    "print(\"Saved: part3_model_results.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}